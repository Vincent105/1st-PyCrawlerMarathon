{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他工具：Grab、PyQuery\n",
    "\n",
    "\n",
    "* 利用 Grab 套件的存取 HTML 資源\n",
    "* 利用 PyQuery 套件的解析 HTML 格式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "將之前用 requests + beatifulsoup 實作的方式，改寫成 grab + pyquery，並且比較有哪些地方不同。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests + BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "力压国安，恒大夺取中超冠军\n"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.zhihu.com/explore'\n",
    "\n",
    "# 加上 Header 即可取回正常資料\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "soup = BeautifulSoup(r.text.replace(r'\\u002F', '/').replace(r'\\u003C', '<').replace(r'\\u003E', '>'),'html.parser')     \n",
    "\n",
    "objects = soup.find('a',class_='ExploreSpecialCard-contentTitle')\n",
    "\n",
    "print(objects.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab + PyQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "取得所有頻道:\n新聞\n股市\n理財\n運動\n名人娛樂\n電影\nYahoo TV\n遊戲\n動漫\n日本代購\n字典\n知識+\n3C科技\n信箱\n氣象\nATM\n公益\n找店+\n訂餐廳\n拍賣\n購物中心\n超級商城\n生活團購\n每日好康\n汽車機車\n中古車\n保險\n時尚美妝\n房地產\n旅遊\n健康\n星座算命\nAPP下載\n網路開店\n買關鍵字\n網路行銷\n聯名卡\n帳號保護\n"
    }
   ],
   "source": [
    "from grab import Grab as gr\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "url = 'https://www.yahoo.com'\n",
    "\n",
    "g = gr()\n",
    "resp = g.go(url,encoding='utf-8')\n",
    "\n",
    "doc = pq(resp.body)\n",
    "span = doc('.drag-item.D-b.Td-n').find(\"span\") \n",
    "\n",
    "print('取得所有頻道:')\n",
    "for item in span.items():\n",
    "    print(item.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}